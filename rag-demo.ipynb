{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1iBisWytQPweetA70yKZN8ZHcJLs_6Q0i","timestamp":1766517203794}],"authorship_tag":"ABX9TyNrwKw0v0ac1ux5ONloI6Su"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"a624727f"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","print(\"âœ… Google Drive Mounted\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"32032ef8"},"source":["%pip install langchain_community"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I3vbqsKn8P22"},"outputs":[],"source":["import os\n","from google.colab import userdata # Or just input your string\n","\n","# Setup the API Key\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n","print(\"âœ… Environment Setup Complete\")"]},{"cell_type":"code","source":["%pip install pypdf\n","from langchain_community.document_loaders import PyPDFLoader\n","\n","# Load the file (Change name to your file)\n","loader = PyPDFLoader('/content/gdrive/MyDrive/training_data/sample_data.pdf')\n","document = loader.load()\n","\n","print(f\"âœ… Document Loaded. Total Pages: {len(document)}\")\n","print(f\"Sample Content from Page 1: {document[0].page_content[:200]}...\")"],"metadata":{"id":"O1JkWzB48ann"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n","chunks = text_splitter.split_documents(document)\n","\n","print(f\"âœ… Document split into {len(chunks)} smaller chunks.\")\n","print(f\"Example Chunk 1: \\n{chunks[0].page_content}\")"],"metadata":{"id":"idJOB6IM_IRL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install langchain_google_genai\n","%pip install langchain_chroma"],"metadata":{"id":"6awloCgS_fTG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_chroma import Chroma\n","\n","# Use the Hugging Face local model\n","embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","\n","# Save chunks into the Vector Database (Chroma)\n","vector_db = Chroma.from_documents(chunks, embeddings)\n","\n","print(\"âœ… Knowledge stored in Chroma (Vector Database).\")"],"metadata":{"id":"CeE3bx-y_bRC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install langchain_google_genai, langchain.chains"],"metadata":{"id":"UQ6-w0TDC8zS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain_classic.chains import RetrievalQA\n","# Initialize Gemini\n","llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n","\n","# Connect the Database to Gemini\n","rag_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vector_db.as_retriever())\n","\n","# Run the Demo\n","query = \"What is the main summary of this document?\"\n","result = rag_chain.invoke(query)\n","\n","print(\"ðŸ¤– Gemini's Answer:\")\n","print(result[\"result\"])"],"metadata":{"id":"QDkq5isLC2iA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n","from langchain_classic.chains import create_retrieval_chain\n","\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.5-flash\",\n","    temperature=0,\n","    max_output_tokens=512\n",")\n","\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a helpful AI assistant. Answer only from the given context.\"),\n","    MessagesPlaceholder(\"chat_history\"),\n","    (\"human\", \"\"\"\n","Context:\n","{context}\n","\n","Question:\n","{question}\n","\"\"\")\n","])\n","\n","doc_chain = create_stuff_documents_chain(llm, prompt)\n","\n","retriever = vector_db.as_retriever(search_kwargs={\"k\": 3})\n","\n","rag_chain = create_retrieval_chain(retriever, doc_chain)\n","\n","chat_history = []\n","\n","query = \"What is the main summary of this document?\"\n","\n","result = rag_chain.invoke({\n","    \"input\": query, # Added 'input' key for the retriever\n","    \"question\": query,\n","    \"chat_history\": chat_history\n","})\n","\n","chat_history.extend([\n","    (\"human\", query),\n","    (\"ai\", result[\"answer\"])\n","])\n","\n","print(result[\"answer\"])"],"metadata":{"id":"bk9IkjbTHB9h"},"execution_count":null,"outputs":[]}]}
